{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0acd382",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at '<a href=\"#papermill-error-cell\">In [7]</a>'.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e975b79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-23T22:48:55.172783Z",
     "iopub.status.busy": "2024-08-23T22:48:55.172522Z",
     "iopub.status.idle": "2024-08-23T22:48:58.192716Z",
     "shell.execute_reply": "2024-08-23T22:48:58.192384Z"
    },
    "papermill": {
     "duration": 3.0279,
     "end_time": "2024-08-23T22:48:58.194984",
     "exception": false,
     "start_time": "2024-08-23T22:48:55.167084",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexandranava/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Jun 11 08:41:55 2024\n",
    "\n",
    "@author: Manasa Kesapragada\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "from keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
    "from keras.optimizers.legacy import Adam\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import pdb\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f7438b",
   "metadata": {
    "papermill": {
     "duration": 0.00221,
     "end_time": "2024-08-23T22:48:58.200647",
     "exception": false,
     "start_time": "2024-08-23T22:48:58.198437",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88c3f1a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-23T22:48:58.207434Z",
     "iopub.status.busy": "2024-08-23T22:48:58.207131Z",
     "iopub.status.idle": "2024-08-23T22:48:58.209273Z",
     "shell.execute_reply": "2024-08-23T22:48:58.208961Z"
    },
    "papermill": {
     "duration": 0.007065,
     "end_time": "2024-08-23T22:48:58.210290",
     "exception": false,
     "start_time": "2024-08-23T22:48:58.203225",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "base = \"/Users/alexandranava/Desktop/Spores/\"\n",
    "model_file = \"/Users/alexandranava/Desktop/Spores/GerminationPrediction/initial_0_V4_Final.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41c56831",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-23T22:48:58.215182Z",
     "iopub.status.busy": "2024-08-23T22:48:58.215040Z",
     "iopub.status.idle": "2024-08-23T22:48:58.258591Z",
     "shell.execute_reply": "2024-08-23T22:48:58.258280Z"
    },
    "papermill": {
     "duration": 0.047221,
     "end_time": "2024-08-23T22:48:58.259741",
     "exception": false,
     "start_time": "2024-08-23T22:48:58.212520",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"/Users/alexandranava/Desktop/Spores/M4581_s1/Analysis/V3/M4581_s1_Model_Data_V2.csv\")\n",
    "df_train = pd.read_csv(\"/Users/alexandranava/Desktop/Spores/M4576_s2/M4576_s2_Model_Data_V2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d7cb7a",
   "metadata": {
    "papermill": {
     "duration": 0.002139,
     "end_time": "2024-08-23T22:48:58.265404",
     "exception": false,
     "start_time": "2024-08-23T22:48:58.263265",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Initialize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "269dd47b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-23T22:48:58.270602Z",
     "iopub.status.busy": "2024-08-23T22:48:58.270447Z",
     "iopub.status.idle": "2024-08-23T22:48:58.277727Z",
     "shell.execute_reply": "2024-08-23T22:48:58.277395Z"
    },
    "papermill": {
     "duration": 0.01153,
     "end_time": "2024-08-23T22:48:58.279054",
     "exception": false,
     "start_time": "2024-08-23T22:48:58.267524",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "columns_to_drop = ['X_POSITION', 'Y_POSITION']\n",
    "df_train = df_train.drop(columns=columns_to_drop)\n",
    "df_test = df_test.drop(columns=columns_to_drop)\n",
    "#df['drug'] = df['drug'].fillna(0)\n",
    "\n",
    "# Reset particle IDs to start from 1\n",
    "df_train['new_spore_id'], unique_ids = pd.factorize(df_train['SPORE_ID'])\n",
    "df_train['new_spore_id'] = df_train['new_spore_id'] + 1\n",
    "\n",
    "df_test['new_spore_id'], unique_ids = pd.factorize(df_test['SPORE_ID'])\n",
    "df_test['new_spore_id'] = df_test['new_spore_id'] + 1\n",
    "\n",
    "# Drop index columns\n",
    "df_train = df_train.drop(['Unnamed: 0'], axis=1)\n",
    "df_test = df_test.drop(['Unnamed: 0'], axis=1)\n",
    "\n",
    "#plt.hist(df_train['PERIMETER'])\n",
    "input_cols = ['INTENSITY','AREA','GERMINANT_EXPOSURE','ELLIPSE_MINOR', \"PERIMETER\", 'GERMINATION']\n",
    "output_cols = 'GERMINATION'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b27870a",
   "metadata": {
    "papermill": {
     "duration": 0.002114,
     "end_time": "2024-08-23T22:48:58.283517",
     "exception": false,
     "start_time": "2024-08-23T22:48:58.281403",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Sensitivity Analysis\n",
    "https://youtu.be/3wNxZcvRdPI?si=anEn6esqAH6it_nN\n",
    "\n",
    "local sensitivity = $\\frac{\\Delta Y}{\\Delta X_i}$ for parameters $X_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78e00742",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-23T22:48:58.288372Z",
     "iopub.status.busy": "2024-08-23T22:48:58.288216Z",
     "iopub.status.idle": "2024-08-23T22:49:00.314486Z",
     "shell.execute_reply": "2024-08-23T22:49:00.314122Z"
    },
    "papermill": {
     "duration": 2.031248,
     "end_time": "2024-08-23T22:49:00.316872",
     "exception": false,
     "start_time": "2024-08-23T22:48:58.285624",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on spores (1, 64)...\n",
      "validating on spores (65, 76)...\n",
      "testing on spores ((1, 54))\n"
     ]
    }
   ],
   "source": [
    "lookback = 3\n",
    "def create_dataset(df, cells, lookback, in_cols= input_cols, out_cols=output_cols, drug_conc=[1]):\n",
    "    trainX, trainY = [], [] #lists of training and testing inputs/outputs\n",
    "    for drug in drug_conc:\n",
    "        for track in range(cells[0], cells[1]):\n",
    "            cell = df.loc[(df[\"new_spore_id\"] == track)] #all rows of data pertaining to this cell\n",
    "            cell = cell[in_cols] #reduce it to our columns of interest\n",
    "            for i in range(len(cell)-lookback-1):\n",
    "                trainX.append(cell[i:i+lookback])\n",
    "            cell = cell[out_cols]\n",
    "            #pdb.set_trace()\n",
    "            for i in range(len(cell)-lookback-1):\n",
    "                trainY.append(cell[i+lookback+1:i+lookback+2])\n",
    "\n",
    "    trainX = np.array(list(map(lambda x: x.to_numpy(), trainX)))\n",
    "    trainY = np.array(list(map(lambda x: x.to_numpy(), trainY)))\n",
    "    return np.array(trainX), np.array(trainY)\n",
    "\n",
    "# calculate data for train with 80% val with 20%\n",
    "num_train_data = len(list(df_train[\"SPORE_ID\"].unique()))\n",
    "train_len = int(num_train_data * 0.85)\n",
    "num_test_data = len(df_test[\"SPORE_ID\"].unique())\n",
    "print(f\"training on spores (1, {train_len})...\")\n",
    "print(f\"validating on spores ({train_len + 1}, {num_train_data})...\")\n",
    "print(f\"testing on spores ({1, num_test_data})\")\n",
    "\n",
    "#training\n",
    "trainX, trainY = create_dataset(df_train,cells=(1, train_len), lookback = 3)\n",
    "valX, valY = create_dataset(df_train, cells=(train_len + 1, num_train_data), lookback = 3)\n",
    "#testing\n",
    "testX, testY = create_dataset(df_test, cells=(1, num_test_data), lookback = 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8183ce6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-23T22:49:00.325188Z",
     "iopub.status.busy": "2024-08-23T22:49:00.325021Z",
     "iopub.status.idle": "2024-08-23T22:49:01.684503Z",
     "shell.execute_reply": "2024-08-23T22:49:01.684190Z"
    },
    "papermill": {
     "duration": 1.364078,
     "end_time": "2024-08-23T22:49:01.685491",
     "exception": false,
     "start_time": "2024-08-23T22:49:00.321413",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  1/536 [..............................] - ETA: 2:06"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 73/536 [===>..........................] - ETA: 0s  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "149/536 [=======>......................] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "232/536 [===========>..................] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "317/536 [================>.............] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "405/536 [=====================>........] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "492/536 [==========================>...] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "536/536 [==============================] - 1s 610us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/94 [..............................] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "80/94 [========================>.....] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "94/94 [==============================] - 0s 638us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  1/473 [..............................] - ETA: 4s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 90/473 [====>.........................] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "182/473 [==========>...................] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "275/473 [================>.............] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "366/473 [======================>.......] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "458/473 [============================>.] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "473/473 [==============================] - 0s 551us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE: 0.08574929257125442\n",
      "Validation RMSE: 0.08574929257125442\n",
      "Testing RMSE: 0.23791547571544325\n",
      "Model number: 0, distance from mean: 0.0\n",
      "Returning model 0, whose distance is 0.0\n"
     ]
    }
   ],
   "source": [
    "#trains numerous models using a list of numbers to initialize the models\n",
    "def typical_model(trainX,trainY,valX,valY,testX,testY,numbers, model_file = None):\n",
    "    models = [] #list of models\n",
    "    predictions = [] #list of prediction vectors\n",
    "\n",
    "    for i in numbers:\n",
    "        \n",
    "        # MODEL TRAINING\n",
    "        if model_file == None: \n",
    "            print('Training model number {}'.format(i))\n",
    "            model = Sequential()\n",
    "            model.add(LSTM(80, input_shape=(trainX.shape[1], trainX.shape[2]))) #(Lookback of 1)\n",
    "            model.add(Dense(1, activation='sigmoid'))\n",
    "            model.add(Dropout(0.01))\n",
    "            model.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "            \n",
    "            early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "            \n",
    "            history = model.fit(trainX, trainY, validation_data=(valX, valY), epochs=30, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
    "            models.append(model)\n",
    "            model.summary()\n",
    "\n",
    "            model.save(\"initial_{}.h5\".format(i))\n",
    "            print(\"Saved model {} to disk\".format(i))\n",
    "\n",
    "            # PLOT TRAINING AND VALIDATION LOSS\n",
    "            loss = history.history['loss']\n",
    "            val_loss = history.history['val_loss']\n",
    "            epochs = range(1, len(loss) + 1)\n",
    "            \n",
    "            plt.figure()\n",
    "            plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "            plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "            plt.title('Training and validation loss for model {}'.format(i))\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "            \n",
    "            # PLOT TRAINING AND VALIDATION ACCURACY\n",
    "            loss = history.history['accuracy']\n",
    "            val_loss = history.history['val_accuracy']\n",
    "            epochs = range(1, len(loss) + 1)\n",
    "            \n",
    "            plt.figure()\n",
    "            plt.plot(epochs, loss, 'bo', label='Training accuracy')\n",
    "            plt.plot(epochs, val_loss, 'b', label='Validation accuracy')\n",
    "            plt.title('Training and validation accuracy for model {}'.format(i))\n",
    "            plt.legend()\n",
    "            plt.show()        \n",
    "        \n",
    "        if model_file != None: \n",
    "            print(\"loading model...\")\n",
    "            model = load_model(model_file)\n",
    "            models.append(model)\n",
    "\n",
    "\n",
    "        #Predict on training, validation, and test sets\n",
    "        trainPredict = model.predict(trainX)\n",
    "        valPredict = model.predict(valX)\n",
    "        testPredict = model.predict(testX)\n",
    "\n",
    "        # Threshold the predictions to get binary outputs\n",
    "        trainPredict_binary = (trainPredict > 0.5).astype(int)\n",
    "        valPredict_binary = (valPredict > 0.5).astype(int)\n",
    "        testPredict_binary = (testPredict > 0.5).astype(int)\n",
    "\n",
    "        # Calculate RMSEs\n",
    "        trainScore = math.sqrt(mean_squared_error(trainY, trainPredict_binary))\n",
    "        print('Training RMSE: {}'.format(trainScore))\n",
    "        valScore = math.sqrt(mean_squared_error(valY, valPredict_binary))\n",
    "        print('Validation RMSE: {}'.format(valScore))\n",
    "        testScore = math.sqrt(mean_squared_error(testY, testPredict_binary))\n",
    "        print('Testing RMSE: {}'.format(testScore))\n",
    "\n",
    "        # add predictions to list of prediction vectors\n",
    "        preds = np.concatenate([trainPredict_binary, valPredict_binary, testPredict_binary], axis=None)\n",
    "        predictions.append(preds)\n",
    "\n",
    "\n",
    "    #find the average of all prediction vectors\n",
    "    mean_pred = np.mean(predictions,axis=0)\n",
    "\n",
    "    #find the prediction vector that is closest to the mean\n",
    "    closest = 0 #index of the prediction vector that is closest to the mean\n",
    "    dist = 100 #the distance of that closest vector to the mean vector\n",
    "    for i in range(len(predictions)):\n",
    "        thisdist = math.sqrt(mean_squared_error(predictions[i], mean_pred))\n",
    "\n",
    "        print('Model number: {}, distance from mean: {}'.format(i,thisdist))\n",
    "\n",
    "        if thisdist < dist:\n",
    "            dist = thisdist\n",
    "            closest = i\n",
    "\n",
    "    #return the \"most average\" model\n",
    "    print('Returning model {}, whose distance is {}'.format(closest,dist))\n",
    "    return models, closest\n",
    "\n",
    "\n",
    "models, closest = typical_model(trainX,trainY,valX,valY,testX,testY,range(1), model_file)\n",
    "model = models[closest]\n",
    "#model.save(\"alex_data_model_lk2.h5\")\n",
    "#model.save(\"alex_data_model_lk2.keras\")\n",
    "#print(\"Saved model to disk\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3889ac",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span id=\"papermill-error-cell\" style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">Execution using papermill encountered an exception here and stopped:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f61a0bb2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-23T22:49:01.691668Z",
     "iopub.status.busy": "2024-08-23T22:49:01.691545Z",
     "iopub.status.idle": "2024-08-23T22:49:02.164905Z",
     "shell.execute_reply": "2024-08-23T22:49:02.164368Z"
    },
    "papermill": {
     "duration": 0.477356,
     "end_time": "2024-08-23T22:49:02.165794",
     "exception": true,
     "start_time": "2024-08-23T22:49:01.688438",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Value after * must be an iterable, not int",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m norm\n\u001b[0;32m----> 3\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m input_cols:\n\u001b[1;32m      5\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfeature\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/matplotlib/pyplot.py:1027\u001b[0m, in \u001b[0;36mfigure\u001b[0;34m(num, figsize, dpi, facecolor, edgecolor, frameon, FigureClass, clear, **kwargs)\u001b[0m\n\u001b[1;32m   1017\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(allnums) \u001b[38;5;241m==\u001b[39m max_open_warning \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1018\u001b[0m     _api\u001b[38;5;241m.\u001b[39mwarn_external(\n\u001b[1;32m   1019\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMore than \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_open_warning\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m figures have been opened. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1020\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFigures created through the pyplot interface \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1024\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConsider using `matplotlib.pyplot.close()`.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1025\u001b[0m         \u001b[38;5;167;01mRuntimeWarning\u001b[39;00m)\n\u001b[0;32m-> 1027\u001b[0m manager \u001b[38;5;241m=\u001b[39m \u001b[43mnew_figure_manager\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1028\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfigsize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfigsize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdpi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdpi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1029\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfacecolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfacecolor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medgecolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medgecolor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframeon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframeon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1030\u001b[0m \u001b[43m    \u001b[49m\u001b[43mFigureClass\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFigureClass\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1031\u001b[0m fig \u001b[38;5;241m=\u001b[39m manager\u001b[38;5;241m.\u001b[39mcanvas\u001b[38;5;241m.\u001b[39mfigure\n\u001b[1;32m   1032\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fig_label:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/matplotlib/pyplot.py:550\u001b[0m, in \u001b[0;36mnew_figure_manager\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Create a new figure manager instance.\"\"\"\u001b[39;00m\n\u001b[1;32m    549\u001b[0m _warn_if_gui_out_of_main_thread()\n\u001b[0;32m--> 550\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_get_backend_mod\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnew_figure_manager\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/matplotlib_inline/backend_inline.py:27\u001b[0m, in \u001b[0;36mnew_figure_manager\u001b[0;34m(num, FigureClass, *args, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnew_figure_manager\u001b[39m(num, \u001b[38;5;241m*\u001b[39margs, FigureClass\u001b[38;5;241m=\u001b[39mFigure, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     22\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;124;03m    Return a new figure manager for a new figure instance.\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \n\u001b[1;32m     25\u001b[0m \u001b[38;5;124;03m    This function is part of the API expected by Matplotlib backends.\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m new_figure_manager_given_figure(num, \u001b[43mFigureClass\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/matplotlib/figure.py:2568\u001b[0m, in \u001b[0;36mFigure.__init__\u001b[0;34m(self, figsize, dpi, facecolor, edgecolor, linewidth, frameon, subplotpars, tight_layout, constrained_layout, layout, **kwargs)\u001b[0m\n\u001b[1;32m   2565\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misfinite(figsize)\u001b[38;5;241m.\u001b[39mall() \u001b[38;5;129;01mor\u001b[39;00m (np\u001b[38;5;241m.\u001b[39marray(figsize) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m   2566\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfigure size must be positive finite not \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   2567\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfigsize\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 2568\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbbox_inches \u001b[38;5;241m=\u001b[39m Bbox\u001b[38;5;241m.\u001b[39mfrom_bounds(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m*\u001b[39mfigsize)\n\u001b[1;32m   2570\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdpi_scale_trans \u001b[38;5;241m=\u001b[39m Affine2D()\u001b[38;5;241m.\u001b[39mscale(dpi)\n\u001b[1;32m   2571\u001b[0m \u001b[38;5;66;03m# do not use property as it will trigger\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: Value after * must be an iterable, not int"
     ]
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "plt.figure(12, 6)\n",
    "for feature in input_cols:\n",
    "  print(f\"Feature: {feature}\")\n",
    "  for std_val in [0.1, 0.5, 1.0]:\n",
    "    print(f\"STD_factor = {std_val}\")\n",
    "    std_dev = (np.std(df_test[feature]) * std_val)\n",
    "    print(f\"{std_dev:.2f}\")\n",
    "    mean = 0 \n",
    "    x = np.linspace(mean - 4*std_dev, mean + 4*std_dev, 1000)\n",
    "    y = norm.pdf(x, mean, std_dev)\n",
    "    plt.plot(x, y, label=f'{std_val}$\\sigma$')\n",
    "  plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d47188",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def local_sensitivity_analysis(df, feature: str, std_factor: int, use_feature_std: int):\n",
    "    \n",
    "    original_data = df.copy()\n",
    "    original_color = \"blue\"\n",
    "    perturbed_color = \"orange\"\n",
    "    # Calculate mean and standard deviation\n",
    "    feature_stddev: float = np.std(df[feature])\n",
    "    feature_mean: float = np.mean(df[feature])\n",
    "\n",
    "    x_min = np.min(df[feature]) - feature_stddev\n",
    "    x_max = np.max(df[feature]) + feature_stddev\n",
    "    \n",
    "    print(rf\"{feature.title()} has std = {feature_stddev}...\")\n",
    "    print(rf\"{feature.title()} has mean = {feature_mean}...\")\n",
    "    \n",
    "    # Choosing std to create Gaussian curve to produce noise\n",
    "    if use_feature_std == 1:\n",
    "        std = feature_stddev * std_factor\n",
    "    else: \n",
    "        std = std_factor\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(14, 4))  # Changed to 2 subplots for distribution plots\n",
    "\n",
    "    ### Adding Noise\n",
    "    print(f\"Using std = {std} to create Gaussian noise...\")\n",
    "    noise = np.random.normal(0, std, df[feature].shape)\n",
    "    print(f\"Adding {df[feature].shape} Gaussian noise samples from {np.min(noise)} to {np.max(noise)}...\")\n",
    "    df[feature] = df[feature] + noise\n",
    "    \n",
    "    #---------------PLOTS\n",
    "    # Plot: Feature distribution before noise\n",
    "    #ax[1].axvline(feature_mean, color='lightgrey', linestyle='--', label=r\"$\\mu$\")\n",
    "    #ax[1].axvline(feature_mean + feature_stddev, color='lightgrey', linestyle='--', label=rf\"+{std_factor}$\\sigma$\")\n",
    "    #ax[1].axvline(feature_mean - feature_stddev, color='lightgrey', linestyle='--', label=rf\"-{std_factor}$\\sigma$\")\n",
    "    \n",
    "    ax[1].hist(original_data[feature], bins=30, alpha=0.25, color=original_color, label = \"Original\")\n",
    "    ax[1].hist(df[feature], bins=30, alpha=0.25, color=perturbed_color, label = \"Perturbed\")\n",
    "    ax[1].set_title(f\"{feature.title()} Distribution\")\n",
    "    ax[1].set_xlabel('Value')\n",
    "    ax[1].set_ylabel('Frequency')\n",
    "    ax[1].set_xlim([x_min, x_max])\n",
    "    ax[1].legend(loc=\"best\")\n",
    "\n",
    "    # Plot: Noise distribution plot\n",
    "    ax[0].axvline(x=std, linestyle=\"--\", color='lightgrey', label=rf\"+$\\sigma$\")\n",
    "    ax[0].axvline(x=-std, linestyle=\"--\", color='lightgrey', label=rf\"-$\\sigma$\")\n",
    "    ax[0].hist(noise, bins=30, alpha=0.75, color='skyblue', edgecolor=\"black\")\n",
    "    ax[0].set_title(rf\"Noise Distribution with $\\sigma$={std:.2f}\")\n",
    "    ax[0].set_xlabel('Noise Value')\n",
    "    ax[0].set_ylabel('Frequency')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    #Plot: Feature before and after perturbation\n",
    "    example_spore_perturbed = df[df[\"new_spore_id\"] == 1]\n",
    "    example_spore_original = original_data[original_data[\"new_spore_id\"]==1]\n",
    "    germination_status = example_spore_original[\"GERMINATION\"].to_list()\n",
    "    example_germination = germination_status.index(1)    \n",
    "    plt.figure(figsize=(6, 4))\n",
    "\n",
    "    sns.lineplot(x=range(0, len(germination_status)), y=example_spore_original[feature], color=original_color, label=\"Original\")\n",
    "    sns.lineplot(x=range(0, len(germination_status)), y=example_spore_perturbed[feature], color=perturbed_color, label=\"Perturbed\", alpha = 0.5)\n",
    "    \n",
    "    plt.axvline(example_germination, color='lightgrey', linestyle='--', label=\"Germination\")\n",
    "    plt.xlabel(\"Frame\")\n",
    "    plt.ylabel(feature.title())\n",
    "    plt.title(f\"{feature.title()} over Time (Spore 1)\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.show()\n",
    "\n",
    "    delta_x = np.mean(np.abs(original_data[feature] - df[feature]))\n",
    "\n",
    "    return df, delta_x\n",
    "\n",
    "sensitivity_feature = \"PERIMETER\"\n",
    "feature_std: int = 0  # 0 to use std_factor directly, 1 to use feature_std * std_factor\n",
    "scale_factor = 0.5  # Scale for std\n",
    "df_test, delta_x = local_sensitivity_analysis(df_test, sensitivity_feature, scale_factor, feature_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0e6a6b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from SALib.sample.morris import sample\n",
    "from SALib.analyze import morris\n",
    "parameter_dict = {'num_vars': 6,\n",
    "                  \"names\": ['INTENSITY','AREA','GERMINANT_EXPOSURE','ELLIPSE_MINOR', \"PERIMETER\", \"GERMINATION\"],\n",
    "                  \"bounds\": [[np.min(df_test[\"INTENSITY\"]), np.max(df_test[\"INTENSITY\"])],\n",
    "                              [np.min(df_test[\"AREA\"]), np.max(df_test[\"AREA\"])],\n",
    "                              [np.min(df_test[\"GERMINANT_EXPOSURE\"]), np.max(df_test[\"GERMINANT_EXPOSURE\"])],\n",
    "                              [np.min(df_test[\"ELLIPSE_MINOR\"]), np.max(df_test[\"ELLIPSE_MINOR\"])],\n",
    "                              [np.min(df_test[\"PERIMETER\"]), np.max(df_test[\"PERIMETER\"])],\n",
    "                              [np.min(df_test[\"GERMINATION\"]), np.max(df_test[\"GERMINATION\"])]]\n",
    "                              }\n",
    "perturbed_input = sample(parameter_dict, 2000)\n",
    "\n",
    "#9am"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3830093",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Predict on training, validation, and test sets\n",
    "trainPredict = model.predict(trainX)\n",
    "trainPredict =(trainPredict > 0.5).astype(int)\n",
    "\n",
    "valPredict = model.predict(valX)\n",
    "valPredict =(valPredict > 0.5).astype(int)\n",
    "\n",
    "testPredict = model.predict(testX)\n",
    "testPredict =(testPredict > 0.5).astype(int)\n",
    "\n",
    "#testPredict = model.predict(perturbed_input)\n",
    "#testPredict = (testPredict > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bcd542",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "$ \\text{True Positive Rate} = \\frac{\\text{TP}}{\\text{TP} + \\text{FN}} $\n",
    "\n",
    "$ \\text{False Positive Rate} = \\frac{\\text{FP}}{\\text{FP} + \\text{TN}} $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe939702",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "\n",
    "$ \\text{Accuracy} = \\frac{\\text{TP} + \\text{TN}}{\\text{TP} + \\text{TN} + \\text{FP} + \\text{FN}} $\n",
    "\n",
    "$ \\text{Precision} = \\frac{\\text{TP}}{\\text{TP} + \\text{FP}} $\n",
    "\n",
    "$ \\text{Recall} = \\frac{\\text{TP}}{\\text{TP} + \\text{FN}} $\n",
    "\n",
    "$ \\text{F1 Score} = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}} $\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc37a0c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Calculate accuracy, precision, recall, and F1-score\n",
    "train_accuracy = accuracy_score(trainY, trainPredict)\n",
    "val_accuracy = accuracy_score(valY, valPredict)\n",
    "test_accuracy = accuracy_score(testY, testPredict)\n",
    "print(\"--------------------\")\n",
    "print(\"Accuracy:\")\n",
    "print('Training Accuracy: {}'.format(train_accuracy))\n",
    "print('Validation Accuracy: {}'.format(val_accuracy))\n",
    "print('Testing Accuracy: {}'.format(test_accuracy))\n",
    "\n",
    "train_precision = precision_score(trainY, trainPredict)\n",
    "val_precision = precision_score(valY, valPredict)\n",
    "test_precision = precision_score(testY, testPredict)\n",
    "print(\"--------------------\")\n",
    "print(\"Precision:\")\n",
    "print('Training Precision: {}'.format(train_precision))\n",
    "print('Validation Precision: {}'.format(val_precision))\n",
    "print('Testing Precision: {}'.format(test_precision))\n",
    "\n",
    "train_recall = recall_score(trainY, trainPredict)\n",
    "val_recall = recall_score(valY, valPredict)\n",
    "test_recall = recall_score(testY, testPredict)\n",
    "print(\"--------------------\")\n",
    "print(\"Recall:\")\n",
    "print('Training Recall: {}'.format(train_recall))\n",
    "print('Validation Recall: {}'.format(val_recall))\n",
    "print('Testing Recall: {}'.format(test_recall))\n",
    "\n",
    "train_f1 = f1_score(trainY, trainPredict)\n",
    "val_f1 = f1_score(valY, valPredict)\n",
    "test_f1 = f1_score(testY, testPredict)\n",
    "print(\"--------------------\")\n",
    "print(\"F1-Score:\")\n",
    "print('Training F1-Score: {}'.format(train_f1))\n",
    "print('Validation F1-Score: {}'.format(val_f1))\n",
    "print('Testing F1-Score: {}'.format(test_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b8156c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve\n",
    "\n",
    "# Plot ROC curve\n",
    "def plot_roc_curve(y_true, y_pred, title):\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_pred)\n",
    "    auc_score = roc_auc_score(y_true, y_pred)\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label=f'ROC curve (area = {auc_score:0.2f})')\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(title)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2873fe",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training set\n",
    "train_auc = roc_auc_score(trainY, trainPredict)\n",
    "print('Training AUC: {}'.format(train_auc))\n",
    "plot_roc_curve(trainY, trainPredict, 'ROC curve - Training set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69fa94b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Validation set\n",
    "val_auc = roc_auc_score(valY, valPredict)\n",
    "print('Validation AUC: {}'.format(val_auc))\n",
    "plot_roc_curve(valY, valPredict, 'ROC curve - Validation set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e43c67",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test set\n",
    "test_auc = roc_auc_score(testY, testPredict)\n",
    "print('Testing AUC: {}'.format(test_auc))\n",
    "plot_roc_curve(testY, testPredict, 'ROC curve - Testing set')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed1b25f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "               Predicted\n",
    "             |   0   |   1   |\n",
    "    --------------------------\n",
    "    True  0  |  TN   |  FP   |\n",
    "    True  1  |  FN   |  TP   |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5035579a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Confusion matrices\n",
    "train_cm = confusion_matrix(trainY, trainPredict)\n",
    "val_cm = confusion_matrix(valY, valPredict)\n",
    "test_cm = confusion_matrix(testY, testPredict)\n",
    "print('Training Confusion Matrix:')\n",
    "print(train_cm)\n",
    "print('Validation Confusion Matrix:')\n",
    "print(val_cm)\n",
    "print('Testing Confusion Matrix:')\n",
    "print(test_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b83d5c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Writing results for model {}'.format(1))\n",
    "maxtrack = int(max(df_test['new_spore_id']))\n",
    "for track in range(1, maxtrack+1):\n",
    "    print(f\"track {track} of {maxtrack}...\")\n",
    "    cell = df_test.loc[(df_test['new_spore_id']==track)]\n",
    "    if len(cell)==0:\n",
    "        continue\n",
    "    maxslice = max(df_test.loc[(df_test['new_spore_id']==track), 'FRAME'])+1\n",
    "    minslice = min(df_test.loc[(df_test['new_spore_id']==track), 'FRAME'])\n",
    "    for sl in range(int(minslice),int(maxslice+1)):\n",
    "        x = cell.loc[(cell['FRAME']>sl-1) & (cell['FRAME']<=sl)]\n",
    "        x = x[input_cols].to_numpy()\n",
    "        if x.size > 0:\n",
    "          x=x.reshape(1, 1, len(input_cols))\n",
    "          df_test.loc[(df_test['new_spore_id']==track) & (df_test['FRAME']==sl), 'pred_germ{}'.format(1)] = model.predict(x)\n",
    " \n",
    "df_test['pred_error{}'.format(1)] = df_test['pred_germ{}'.format(1)] - df_test['GERMINATION']\n",
    "df_test['pred_germ1'] =(df_test['pred_germ1'] > 0.5).astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5632d538",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Plot of Predicted Spores Germinated against Actual Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36284ff2",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.errorbar(df_test['FRAME'].unique(),df_test.groupby(['FRAME']).mean()['pred_germ1'],\n",
    "            color = 'b', label = 'Predicted values')\n",
    "plt.errorbar(df_test['FRAME'].unique(),df_test.groupby(['FRAME']).mean()['GERMINATION'],\n",
    "             color = 'orange', label = 'Original values')\n",
    "plt.yticks(fontsize=20)\n",
    "plt.xlabel('Timestep',fontsize=14)\n",
    "plt.ylabel('Mean spores germinated',fontsize=14)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0e4781",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get unique spore IDs\n",
    "unique_spore_ids = df_test['new_spore_id'].unique()\n",
    "\n",
    "# list of correct spores\n",
    "spore_error: list[0, 1] = []\n",
    "\n",
    "# Loop through each spore ID and create separate plots\n",
    "for spore_id in unique_spore_ids:\n",
    "    spore_data = df_test[df_test['new_spore_id'] == spore_id]\n",
    "    \n",
    "    # Create a new figure for each spore ID\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    \n",
    "    # Plot GERMINATION values\n",
    "    ax.errorbar(\n",
    "        spore_data['FRAME'].unique(),\n",
    "        spore_data.groupby(['FRAME']).mean()['GERMINATION'],\n",
    "        yerr=spore_data.groupby(['FRAME']).sem()['GERMINATION'],\n",
    "        color='red',\n",
    "        linewidth = 5,\n",
    "        label='Original GERMINATION values'\n",
    "    )\n",
    "    \n",
    "    # Plot pred_germ1 values\n",
    "    ax.errorbar(\n",
    "        spore_data['FRAME'].unique(),\n",
    "        spore_data.groupby(['FRAME']).mean()['pred_germ1'],\n",
    "        yerr=spore_data.groupby(['FRAME']).sem()['pred_germ1'],\n",
    "        color='black',\n",
    "        linewidth = 3,\n",
    "        label='Predicted GERMINATION values'\n",
    "    )\n",
    "\n",
    "    # Set plot title and labels\n",
    "    ax.set_title(f'Spore ID {spore_id} - GERMINATION')\n",
    "    ax.set_xlabel('FRAME')\n",
    "    ax.set_ylabel('Values')\n",
    "    ax.legend()\n",
    "\n",
    "    #add 1 for correct and 0 for wrong\n",
    "    binary_error = int((spore_data['GERMINATION'].mean() == spore_data['pred_germ1'].mean()))\n",
    "    if binary_error == 0:\n",
    "        print(spore_id)\n",
    "    spore_error.append(binary_error)\n",
    "    \n",
    "\n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf4e308",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Accuracy on test data \n",
    "correct_percentage = (sum(spore_error) / len(spore_error)) * 100\n",
    "print(f\"{correct_percentage}% of spores predicted correctly...\")\n",
    "number_wrong = spore_error.count(0)\n",
    "print(f\"{number_wrong} spores incorrectly predicted...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb43a5b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if feature_std == 1:\n",
    "    sensitivity_csv = f\"{base}/Analysis/sensitivity_featurestd.csv\"\n",
    "if feature_std == 0:  # Use else instead of another if\n",
    "    sensitivity_csv = f\"{base}/Analysis/sensitivity_gaussian.csv\"\n",
    "\n",
    "accuracy = {\n",
    "    \"Feature\": [sensitivity_feature],\n",
    "    \"Accuracy\": [correct_percentage],\n",
    "    \"STD\": [feature_std * scale_factor],\n",
    "    \"Delta x\": [delta_x]\n",
    "    }\n",
    "\n",
    "accuracy_df = pd.DataFrame(accuracy)\n",
    "\n",
    "# Ensure that a newline is correctly added before appending\n",
    "# with open(sensitivity_csv, 'a') as f:\n",
    "#     if os.path.getsize(sensitivity_csv) > 0:  # Check if file is non-empty\n",
    "#         f.write('\\n')  # Ensure a newline is added before appending\n",
    "\n",
    "accuracy_df.to_csv(sensitivity_csv, index=False, mode=\"a\", header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8.464028,
   "end_time": "2024-08-23T22:49:02.791554",
   "environment_variables": {},
   "exception": true,
   "input_path": "/Users/alexandranava/Desktop/Spores/GerminationPrediction/Preliminary_LSTM.ipynb",
   "output_path": "/Users/alexandranava/Desktop/Spores/GerminationPrediction/Preliminary_LSTM_run_7.ipynb",
   "parameters": {},
   "start_time": "2024-08-23T22:48:54.327526",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}